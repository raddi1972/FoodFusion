{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load the CSV file into a pandas DataFrame\ndf1 = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/RAW_recipes.csv')\ndf2 = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/RAW_interactions.csv')\n# Print the first five rows of the DataFrame to check if the data was loaded correctly\ndf1.head()","metadata":{"id":"UyzjMx4K8Xdu","outputId":"8fdf867a-4bf0-4acd-a3fe-6a8e90e16784","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-04-27T10:42:52.427719Z","iopub.execute_input":"2023-04-27T10:42:52.428100Z","iopub.status.idle":"2023-04-27T10:43:00.350690Z","shell.execute_reply.started":"2023-04-27T10:42:52.428064Z","shell.execute_reply":"2023-04-27T10:43:00.349575Z"},"trusted":true},"execution_count":194,"outputs":[{"execution_count":194,"output_type":"execute_result","data":{"text/plain":"                                         name      id  minutes  \\\n0  arriba   baked winter squash mexican style  137739       55   \n1            a bit different  breakfast pizza   31490       30   \n2                   all in the kitchen  chili  112140      130   \n3                          alouette  potatoes   59389       45   \n4          amish  tomato ketchup  for canning   44061      190   \n\n   contributor_id   submitted  \\\n0           47892  2005-09-16   \n1           26278  2002-06-17   \n2          196586  2005-02-25   \n3           68585  2003-04-14   \n4           41706  2002-10-25   \n\n                                                tags  \\\n0  ['60-minutes-or-less', 'time-to-make', 'course...   \n1  ['30-minutes-or-less', 'time-to-make', 'course...   \n2  ['time-to-make', 'course', 'preparation', 'mai...   \n3  ['60-minutes-or-less', 'time-to-make', 'course...   \n4  ['weeknight', 'time-to-make', 'course', 'main-...   \n\n                                    nutrition  n_steps  \\\n0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n3   [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n4   [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n\n                                               steps  \\\n0  ['make a choice and proceed with recipe', 'dep...   \n1  ['preheat oven to 425 degrees f', 'press dough...   \n2  ['brown ground beef in large pot', 'add choppe...   \n3  ['place potatoes in a large pot of lightly sal...   \n4  ['mix all ingredients& boil for 2 1 / 2 hours ...   \n\n                                         description  \\\n0  autumn is my favorite time of year to cook! th...   \n1  this recipe calls for the crust to be prebaked...   \n2  this modified version of 'mom's' chili was a h...   \n3  this is a super easy, great tasting, make ahea...   \n4  my dh's amish mother raised him on this recipe...   \n\n                                         ingredients  n_ingredients  \n0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n2  ['ground beef', 'yellow onions', 'diced tomato...             13  \n3  ['spreadable cheese with garlic and herbs', 'n...             11  \n4  ['tomato juice', 'apple cider vinegar', 'sugar...              8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>id</th>\n      <th>minutes</th>\n      <th>contributor_id</th>\n      <th>submitted</th>\n      <th>tags</th>\n      <th>nutrition</th>\n      <th>n_steps</th>\n      <th>steps</th>\n      <th>description</th>\n      <th>ingredients</th>\n      <th>n_ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>arriba   baked winter squash mexican style</td>\n      <td>137739</td>\n      <td>55</td>\n      <td>47892</td>\n      <td>2005-09-16</td>\n      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n      <td>11</td>\n      <td>['make a choice and proceed with recipe', 'dep...</td>\n      <td>autumn is my favorite time of year to cook! th...</td>\n      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a bit different  breakfast pizza</td>\n      <td>31490</td>\n      <td>30</td>\n      <td>26278</td>\n      <td>2002-06-17</td>\n      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n      <td>9</td>\n      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n      <td>this recipe calls for the crust to be prebaked...</td>\n      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all in the kitchen  chili</td>\n      <td>112140</td>\n      <td>130</td>\n      <td>196586</td>\n      <td>2005-02-25</td>\n      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n      <td>6</td>\n      <td>['brown ground beef in large pot', 'add choppe...</td>\n      <td>this modified version of 'mom's' chili was a h...</td>\n      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>alouette  potatoes</td>\n      <td>59389</td>\n      <td>45</td>\n      <td>68585</td>\n      <td>2003-04-14</td>\n      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n      <td>[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]</td>\n      <td>11</td>\n      <td>['place potatoes in a large pot of lightly sal...</td>\n      <td>this is a super easy, great tasting, make ahea...</td>\n      <td>['spreadable cheese with garlic and herbs', 'n...</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>amish  tomato ketchup  for canning</td>\n      <td>44061</td>\n      <td>190</td>\n      <td>41706</td>\n      <td>2002-10-25</td>\n      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n      <td>[352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]</td>\n      <td>5</td>\n      <td>['mix all ingredients&amp; boil for 2 1 / 2 hours ...</td>\n      <td>my dh's amish mother raised him on this recipe...</td>\n      <td>['tomato juice', 'apple cider vinegar', 'sugar...</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df3 = pd.read_csv('/content/drive/MyDrive/rs_final/PP_users.csv')","metadata":{"id":"15FP8YyYfUAt","execution":{"iopub.status.busy":"2023-04-27T10:43:00.352662Z","iopub.execute_input":"2023-04-27T10:43:00.354508Z","iopub.status.idle":"2023-04-27T10:43:00.359205Z","shell.execute_reply.started":"2023-04-27T10:43:00.354464Z","shell.execute_reply":"2023-04-27T10:43:00.358121Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/RAW_recipes.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:43:00.362557Z","iopub.execute_input":"2023-04-27T10:43:00.362879Z","iopub.status.idle":"2023-04-27T10:43:00.371701Z","shell.execute_reply.started":"2023-04-27T10:43:00.362848Z","shell.execute_reply":"2023-04-27T10:43:00.370654Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"print(df1['minutes'][0])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:43:00.374814Z","iopub.execute_input":"2023-04-27T10:43:00.375259Z","iopub.status.idle":"2023-04-27T10:43:00.383637Z","shell.execute_reply.started":"2023-04-27T10:43:00.375194Z","shell.execute_reply":"2023-04-27T10:43:00.382542Z"},"trusted":true},"execution_count":197,"outputs":[{"name":"stdout","text":"55\n","output_type":"stream"}]},{"cell_type":"code","source":"df1.columns.values","metadata":{"id":"v_ORg2tJ9xye","outputId":"23fe6cf8-daed-48bc-c810-1f449b5e170c","execution":{"iopub.status.busy":"2023-04-27T10:43:00.385084Z","iopub.execute_input":"2023-04-27T10:43:00.385755Z","iopub.status.idle":"2023-04-27T10:43:00.397618Z","shell.execute_reply.started":"2023-04-27T10:43:00.385715Z","shell.execute_reply":"2023-04-27T10:43:00.396550Z"},"trusted":true},"execution_count":198,"outputs":[{"execution_count":198,"output_type":"execute_result","data":{"text/plain":"array(['name', 'id', 'minutes', 'contributor_id', 'submitted', 'tags',\n       'nutrition', 'n_steps', 'steps', 'description', 'ingredients',\n       'n_ingredients'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"df1 = df1.drop(['contributor_id', 'submitted', 'tags', 'n_steps', 'steps',\n       'n_ingredients'], axis=1)","metadata":{"id":"pP8zWHJo9n5p","outputId":"b3a4354a-2816-46cd-d1b3-cc671a0f69b7","execution":{"iopub.status.busy":"2023-04-27T10:43:00.399265Z","iopub.execute_input":"2023-04-27T10:43:00.399624Z","iopub.status.idle":"2023-04-27T10:43:00.427272Z","shell.execute_reply.started":"2023-04-27T10:43:00.399573Z","shell.execute_reply":"2023-04-27T10:43:00.426174Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\n","metadata":{"id":"bko7bX9DQnDZ","outputId":"b50642d3-47bd-42a8-c727-afec86c938e5","execution":{"iopub.status.busy":"2023-04-27T10:43:00.429164Z","iopub.execute_input":"2023-04-27T10:43:00.429610Z","iopub.status.idle":"2023-04-27T10:43:00.480555Z","shell.execute_reply.started":"2023-04-27T10:43:00.429558Z","shell.execute_reply":"2023-04-27T10:43:00.479420Z"},"trusted":true},"execution_count":200,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":200,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"for i in df1.index:\n  nutri = df1.at[i,'nutrition']\n  ingred = df1.at[i,'ingredients']\n  # print(type(item))\n  nutri = nutri.replace('[','')\n  ingred = ingred.replace('[\\'','')\n  nutri = nutri.replace(']','')\n  ingred = ingred.replace('\\']','')\n  nutri = nutri.split(', ')\n  ingred = ingred.split('\\', \\'')\n  df1.at[i,'nutrition']=[float(i) for i in nutri]\n  df1.at[i,'ingredients']=ingred","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:43:00.482172Z","iopub.execute_input":"2023-04-27T10:43:00.482644Z","iopub.status.idle":"2023-04-27T10:43:09.159780Z","shell.execute_reply.started":"2023-04-27T10:43:00.482604Z","shell.execute_reply":"2023-04-27T10:43:09.158717Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"nutri_sum = np.array([0.0,0.0,0.0,0.0,0.0,0.0,0.0])\nfor i in df1.index:\n    lst = df1.at[i,'nutrition']\n    nutri_sum+=np.array(lst)\nnutri_sum= nutri_sum/len(df1)\nprint(nutri_sum)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:43:09.163029Z","iopub.execute_input":"2023-04-27T10:43:09.163645Z","iopub.status.idle":"2023-04-27T10:43:10.857496Z","shell.execute_reply.started":"2023-04-27T10:43:09.163611Z","shell.execute_reply":"2023-04-27T10:43:10.856474Z"},"trusted":true},"execution_count":202,"outputs":[{"name":"stdout","text":"[473.94242457  36.08069954  84.29686535  30.14748507  34.68185998\n  45.58915027  15.5604027 ]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(df1.at[0,'nutrition'][0]))","metadata":{"execution":{"iopub.status.busy":"2023-04-27T10:43:10.862029Z","iopub.execute_input":"2023-04-27T10:43:10.862355Z","iopub.status.idle":"2023-04-27T10:43:10.869966Z","shell.execute_reply.started":"2023-04-27T10:43:10.862324Z","shell.execute_reply":"2023-04-27T10:43:10.868909Z"},"trusted":true},"execution_count":203,"outputs":[{"name":"stdout","text":"<class 'float'>\n","output_type":"stream"}]},{"cell_type":"code","source":"import gensim\nfrom nltk.corpus import stopwords\n\n# Join the list of words in the \"ingredients\" column into a string\ndf1['ingredients_str'] = df1['ingredients'].apply(lambda x: ' '.join(x))\n\n# Concatenate the \"description\" and \"ingredients\" columns into a single text item\ndf1['text'] = df1['description'] + ' ' + df1['ingredients_str']\ndf1['text'] = df1['text'].astype(str)\n\n# Tokenize the text\ntokenizer = nltk.RegexpTokenizer(r'\\w+')\ndf1['tokens'] = df1['text'].apply(lambda x: tokenizer.tokenize(x.lower()))\n\n# Remove stop words and punctuations \nstop_words = set(stopwords.words('english'))\ndf1['tokens'] = df1['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n\n# Train the Word2Vec model\nmodel = gensim.models.Word2Vec(df1['tokens'].tolist(), min_count=1, vector_size=100, workers=4)","metadata":{"id":"onmXlIUvPoVq","execution":{"iopub.status.busy":"2023-04-27T10:43:10.871601Z","iopub.execute_input":"2023-04-27T10:43:10.872730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate word embeddings for each text item in the dataframe\n# df1['embedding'] = df1['tokens'].apply(lambda x: [model[word] for word in x if word in model.wv.key_to_index])\ndf1['embedding'] = df1['tokens'].apply(lambda x: [model.wv[word] for word in x if word in model.wv.key_to_index])\n\n","metadata":{"id":"Vven_IQyR1Nx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"usr_rating ={}\nfor i in df2.index:\n    uid= df2.at[i,'user_id']\n    rate = df2.at[i,'rating']\n    if(usr_rating.get(uid)==None):\n        usr_rating[uid]=[rate]\n    else:\n        usr_rating[uid].append(rate)\n        \nusr_std = {}\nfor key in usr_rating:\n    if(usr_std.get(key)==None):\n        usr_std[key]=np.std(usr_rating[key])\n\nusr_avg ={}\nusr_cnt={}\n\nfor i in df2.index:\n    uid= df2.at[i,'user_id']\n    rate = df2.at[i,'rating']\n    if(usr_avg.get(uid)==None):\n        usr_cnt[uid]=1\n        usr_avg[uid]=rate\n    else:\n        usr_cnt[uid]+=1\n        usr_avg[uid]+=rate\n\nfor key in usr_avg:\n    usr_avg[key]=usr_avg[key]/usr_cnt[key]\n    usr_avg[key]=round(usr_avg[key],2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_rating = {}\nfor i in df2.index:\n    uid=df2.at[i,'user_id']\n    rate = df2.at[i,'rating']\n    if(usr_std[uid]!=0):\n        df2.at[i,'rating'] = round((rate-usr_avg[uid])/usr_std[uid],2)\n    else:\n        df2.at[i,'rating'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"id":"S4oiiopGWBEK","outputId":"3a439799-1134-4f93-84a2-0820317368cc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merged_df = pd.merge(df1, df2, left_on='id', right_on='recipe_id')","metadata":{"id":"j_5CShKh8Xdy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df1.drop_duplicates(inplace=True)","metadata":{"id":"H0tX6tT39d3g","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df3.head()","metadata":{"id":"9JdwqdKDW6lV","outputId":"ee67786c-783a-49be-d070-3c92d1b0f8f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for item in df3['items']:\n#   item = item.replace('[','')\n#   item = item.replace(']','')\n#   item = item.split(',')\n#   # print(item)\n\n# print(map)","metadata":{"id":"etWJElLZWTmU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df3.at[0,'items'][5]","metadata":{"id":"iz4ysgJqaabc","outputId":"93a6f985-b8de-4da7-e9f3-6830aaa9fe44","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# map = {}\n\n# for i in df3.index:\n#   item = df3.at[i,'items']\n#   rating = df3.at[i,'ratings']\n#   # print(type(item))\n#   item = item.replace('[','')\n#   rating = rating.replace('[','')\n#   item = item.replace(']','')\n#   rating = rating.replace(']','')\n#   item = item.split(', ')\n#   rating = rating.split(', ')\n#   df3.at[i,'items']=item\n#   df3.at[i,'ratings']=rating\n#   for recipe in item:\n#     if(map.get(recipe)==None):\n#       map[recipe] = 1\n#     else:\n#       map[recipe]+=1\n#   # print(i)","metadata":{"id":"zq40dO08Jwc9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"id":"mc_h8lXWFYxM","outputId":"b7124c4d-a82a-444c-8765-551be4988536","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map = {}\nfor i in df2.index:\n  rid = df2.at[i,'recipe_id']\n  if(map.get(rid)==None):\n    map[rid] = 1;\n  else:\n    map[rid]+=1;","metadata":{"id":"ez-8WvmuFR3x","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_recipes = sorted(map,key= map.get, reverse=True)\nsorted_recipes = sorted_recipes[:20]\nprint(sorted_recipes)","metadata":{"id":"-IhoZOe-ZohY","outputId":"2dc0127a-c6c8-448f-a1f3-0ce54fbba03c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top20 = []\nfor idx in sorted_recipes:\n    top20.append(df1.at[df1.index.values[df1['id']==idx][0],'name'])\nprint(top20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# user_embeddings = {}\n# for i in df3.index:\n#   user_embeddings[i]=[]\n#   for recipe in sorted_recipes:\n#     if recipe in df3.at[i,'items']:\n#       user_embeddings[i].append(int(df3.at[i,'ratings'][df3.at[i,'items'].index(recipe)])\n#     else:\n#       user_embeddings[i].append(0) # can be replaced with mean ratings of the user\n# print(user_embeddings)\n# print(map['99787'])","metadata":{"id":"xFn7u7AlUTU1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_embeddings = {}\nuser_who_rated = {}\nfor i in df2.index:\n  uid = df2.at[i,'user_id']\n  user_embeddings[uid] = [0 for i in range(20)]\n  user_who_rated[uid] = 0\n","metadata":{"id":"B9Ew3m0BF45o","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df2.index:\n  uid = df2.at[i,'user_id']\n  rid = df2.at[i,'recipe_id']\n  rating = df2.at[i,'rating']\n  if rid in sorted_recipes:\n    ind = sorted_recipes.index(rid)\n    lst = user_embeddings[uid]\n    lst[ind] = rating\n    user_embeddings[uid] = lst\n    user_who_rated[uid] = user_who_rated[uid] + 1\n","metadata":{"id":"RI35wI6kH04M","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df2.index:\n  rid = df2.at[i,'recipe_id']\n  if(rid == 27208): \n    print(df2.iloc[i])\n    break","metadata":{"id":"fi_Tk5aTIov6","outputId":"c0a3fe47-af59-409d-b5c4-de63ec8db335","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_embeddings.get(103224)","metadata":{"id":"lppdnMPuf5lP","outputId":"f7a957eb-f521-47ce-84a7-2efdfe3c2597","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_avg = []\ncount = 0;\nfor i in df1.index:\n  list_of_lists = df1.at[i,'embedding']\n  # Create a new list with zeros of the same length as the sublists\n  avg_list = [0] * len(list_of_lists[0])\n\n  # Calculate the sum of each element across all sublists\n  for sublist in list_of_lists:\n      for i, num in enumerate(sublist):\n          avg_list[i] += num\n\n  # Divide each element by the number of sublists to get the average\n  avg_list = [x / len(list_of_lists) for x in avg_list]\n  emb_avg.append(avg_list)\n  if(count%10000 == 0):\n    print(count)\n  count = count + 1\n","metadata":{"id":"QDxQdXudYTPi","outputId":"d2520643-a170-4c32-bc76-7706f5161515","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df1['emb_avg'] = df1['embedding'].apply(lambda x: [sum(sublist)/len(sublist) for sublist in x])","metadata":{"id":"CxT8hfyUKN_0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['emb_avg'] = emb_avg","metadata":{"id":"qEtyc8OCdLJQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_embeddings = {}\nfor i in df1.index:\n  uid = df1.at[i,'id']\n  item_embeddings[uid] = df1.at[i,'emb_avg']","metadata":{"id":"tdGM5QC9epm5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.shape","metadata":{"id":"fbIoNU7UMn0e","outputId":"a707d9f3-c7ca-4387-8ebd-f97afe9817fc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []\ny = []\nfor i in df2.index:\n  uid = df2.at[i,'user_id']\n  rid = df2.at[i,'recipe_id']\n  rating = df2.at[i,'rating']\n  if(user_who_rated[uid]>4):\n        X.append(user_embeddings.get(uid) + item_embeddings.get(rid))\n        y.append(rating)","metadata":{"id":"QtzXHpzlds7G","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X)","metadata":{"id":"BDjZ3b-IfiXL","outputId":"b49b7bf9-ae1c-424f-9621-7f1c6917033f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)\ny = np.array(y)","metadata":{"id":"Ky6RXMELgoub","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the mean of each column, excluding zeros\ncol_means = np.true_divide(X.sum(0), (X != 0).sum(0))\n\n# Replace zeros with column means\nX[X == 0] = np.take(col_means, np.where(X == 0)[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[0][:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X, test_X = train_test_split(X, test_size=0.2, random_state=42)\ntrain_y, test_y = train_test_split(y, test_size=0.2, random_state=42)\n","metadata":{"id":"OcDl-CAFg2I6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nmodel = LGBMRegressor(num_iterations=2000,learning_rate=0.05,n_estimators=500,num_leaves=64,max_depth=18)\nmodel.fit(train_X, train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Make predictions on the training data\ntrain_y_pred = model.predict(train_X)\n# Round off the predictions\ntrain_y_pred = np.round(train_y_pred)\n# Calculate the training accuracy\ntrain_accuracy = accuracy_score(train_y, train_y_pred)\n\n# Make predictions on the testing data\ntest_y_pred = model.predict(test_X)\n# Round off the predictions\ntest_y_pred = np.round(test_y_pred)\n# Calculate the testing accuracy\ntest_accuracy = accuracy_score(test_y, test_y_pred)\n\nprint(f'Training Accuracy: {train_accuracy}')\nprint(f'Testing Accuracy: {test_accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xg\nxgb_r = xg.XGBRegressor(num_iterations=1000,learning_rate=0.05,n_estimators=200,num_leaves=64,max_depth=12)\nxgb_r.fit(train_X, train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Make predictions on the training data\ntrain_y_pred = xgb_r.predict(train_X)\n# Round off the predictions\ntrain_y_pred = np.round(train_y_pred)\n# Calculate the training accuracy\ntrain_accuracy = accuracy_score(train_y, train_y_pred)\n\n# Make predictions on the testing data\ntest_y_pred = xgb_r.predict(test_X)\n# Round off the predictions\ntest_y_pred = np.round(test_y_pred)\n# Calculate the testing accuracy\ntest_accuracy = accuracy_score(test_y, test_y_pred)\n\nprint(f'Training Accuracy: {train_accuracy}')\nprint(f'Testing Accuracy: {test_accuracy}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.shape","metadata":{"id":"gH4ref20hQoA","outputId":"cc5ab737-7ee4-4e0c-a354-e8f043313c91","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X_tensor = torch.tensor(train_X, dtype=torch.float32).to(\"cuda\")\ntrain_y_tensor = torch.tensor(train_y, dtype=torch.float32).unsqueeze(1).to(\"cuda\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_X_tensor = torch.tensor(test_X, dtype=torch.float32).to(\"cuda\")\ntest_y_tensor = torch.tensor(test_y, dtype=torch.float32).unsqueeze(1).to(\"cuda\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losslst = []\nclass RegressionNet(nn.Module):\n    def __init__(self):\n        super(RegressionNet, self).__init__()\n        self.hidden1 = nn.Linear(120, 256)\n        self.batchnorm1 = nn.BatchNorm1d(256)\n        self.dropout1 = nn.Dropout(0.3)\n        self.hidden2 = nn.Linear(256, 128)\n        self.batchnorm2 = nn.BatchNorm1d(128)\n        self.dropout2 = nn.Dropout(0.2)\n        self.hidden5 = nn.Linear(128, 92)\n        self.batchnorm5 = nn.BatchNorm1d(92)\n        self.dropout5 = nn.Dropout(0.15)\n        self.hidden3 = nn.Linear(92, 64)\n        self.batchnorm3 = nn.BatchNorm1d(64)\n        self.dropout3 = nn.Dropout(0.1)\n        self.hidden4 = nn.Linear(64, 32)\n        self.batchnorm4 = nn.BatchNorm1d(32)\n        self.dropout4 = nn.Dropout(0.05)\n        self.output = nn.Linear(32, 1)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.hidden1(x)\n        x = self.batchnorm1(x)\n        x = self.dropout1(x)\n        x = self.relu(x)\n        x = self.hidden2(x)\n        x = self.batchnorm2(x)\n        x = self.dropout2(x)\n        x = self.relu(x)\n        x = self.hidden5(x)\n        x = self.batchnorm5(x)\n        x = self.dropout5(x)\n        x = self.relu(x)\n        x = self.hidden3(x)\n        x = self.batchnorm3(x)\n        x = self.dropout3(x)\n        x = self.relu(x)\n        x = self.hidden4(x)\n        x = self.batchnorm4(x)\n        x = self.dropout4(x)\n        x = self.relu(x)\n        x = self.output(x)\n        return x\n\n# Create an instance of the model\nmodel = RegressionNet().to(\"cuda\")\n\n# Define the loss function and optimizer\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n\n# Train the model\nbatch_size = 128\nnum_epochs = 200\nnum_batches = int(len(train_X_tensor) / batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    for batch in range(num_batches):\n        # Generate mini-batch\n        batch_X = train_X_tensor[batch * batch_size : (batch + 1) * batch_size]\n        batch_y = train_y_tensor[batch * batch_size : (batch + 1) * batch_size]\n\n        # Forward pass\n        outputs = model(batch_X)\n        loss = criterion(outputs, batch_y)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    # Evaluate the model on the training set\n    with torch.no_grad():\n        train_outputs = model(train_X_tensor)\n        train_loss = criterion(train_outputs, train_y_tensor)\n        train_acc = 1 - train_loss.item() / torch.mean((train_y_tensor - torch.mean(train_y_tensor))**2).item()\n    losslst.append(train_loss.item())\n    print(f\"Epoch {epoch+1} - Training loss: {train_loss.item()}, Training accuracy: {train_acc}\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(losslst[:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set\nwith torch.no_grad():\n    test_outputs = model(test_X_tensor)\n    test_loss = criterion(test_outputs, test_y_tensor)\n    test_acc = 1 - test_loss.item() / torch.mean((test_y_tensor - torch.mean(test_y_tensor))**2).item()\n\nprint(f\"Test loss: {test_loss.item()}, Test accuracy: {test_acc}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the predicted output on the training data\ntrain_outputs = model(train_X_tensor)\n\n# Convert the predicted output and the training target to numpy arrays\ntrain_outputs_np = train_outputs.to(\"cpu\").detach().numpy()\ntrain_y_np = train_y_tensor.to(\"cpu\").detach().numpy()\n\n# Round the predicted output to the nearest integer\ntrain_outputs_rounded = np.round(train_outputs_np)\n\n# Calculate the number of correct predictions\nnum_correct = np.sum(train_outputs_rounded == train_y_np)\n\n# Calculate the training accuracy\naccuracy = num_correct / len(train_y_np)\nprint(f\"Training accuracy: {accuracy:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(test_y_np)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_outputs = model(test_X_tensor)\n\n# Convert the predicted output and the training target to numpy arrays\ntest_outputs_np = test_outputs.to(\"cpu\").detach().numpy()\ntest_y_np = test_y_tensor.to(\"cpu\").detach().numpy()\n\n# Round the predicted output to the nearest integer\ntest_outputs_rounded = np.round(test_outputs_np)\n\n# Calculate the number of correct predictions\nnum_correct = 0\nfor i in range(len(test_outputs_rounded)):\n    if(train_outputs_rounded[i] == test_y_np[i]):\n        num_correct = num_correct+1\n\n# # Calculate the training accuracy\naccuracy = num_correct / len(test_y_np)\nprint(f\"Testing accuracy: {accuracy:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_outputs_rounded[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_y_np[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newuser = [0,0,3,5,1,0,2,2,5,1,3,3,3,0,0,2,4,2,1,4]\nstand=np.std(newuser)\nstand\nmean=np.mean(newuser)\nif(stand!=0):\n    for i in range(len(newuser)):\n        newuser[i]=(newuser[i]-mean)/stand\nnew_ingredients = ['onion', 'gingerroot', 'garam masala','beef','steak', 'tomato paste', 'chicken stock', 'single cream', 'boneless chicken breasts', 'salt & pepper', 'butter','eggs','tomato paste','prepared pizza crust','butter','garam masala','salt', 'flour', 'garlic powder', 'oil', 'chicken rice soup']\nnutrition_sensitivity = 0.9\ntime_needed = 1000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(df1.at[0,'nutrition'][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avail_recipes=[]\nfor i in df1.index:\n    recipe_ingred = df1.at[i,'ingredients']\n    time = df1.at[i,'minutes']\n#     print(recipe_ingred)\n    flag = 0\n    for j in recipe_ingred:\n        if j not in new_ingredients:\n            flag = 1\n            break\n    if (flag == 0 and time<time_needed):\n        avail_recipes.append(df1.at[i,'id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(avail_recipes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df1.at[df1.index.values[df1['id']==309425][0],'name'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newuser_dataset = []\nnutri_values = []\nfor rid in avail_recipes:\n    newuser_dataset.append(newuser+item_embeddings[rid])\n    nutri_values.append(df1.at[df1.index.values[df1['id']==rid][0],'nutrition'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print((nutri_values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newuser_dataset_tensor = torch.tensor(newuser_dataset, dtype=torch.float32).to(\"cuda\")\nnew_outputs = model(newuser_dataset_tensor)\n\n# Convert the predicted output and the training target to numpy arrays\nnew_outputs_np = new_outputs.to(\"cpu\").detach().numpy()\nnew_outputs_np = new_outputs_np.flatten()\ndomain = []\nratings_pred = []\ndomain.append(np.min(new_outputs_np))\ndomain.append(np.max(new_outputs_np))\nrng = 1\nif (domain[1]-domain[0])!=0:\n    rng = (domain[1]-domain[0])\nfor i in new_outputs_np:\n    ratings_pred.append((i-domain[0])/rng)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ratings_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calorie,total fat,sugar,sodium,protein,saturated fat,carbs(pdv)\nbalanced_diet = [1.0,0.5,1.0,0.5,1.0,0.5,0.5]\nhigh_protein = [1.0,0.5,0.5,0.5,3,0.5,1.5]\nmean = [473.94242457,36.08069954,84.29686535,30.14748507,34.68185998,45.58915027,15.5604027] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nutri_score = []\nfor i in range(len(new_outputs_np)):\n    score = 0.0\n    for j in range(len(nutri_values[0])):\n        score+=(nutri_values[i][j]*high_protein[j])/mean[j]\n#     print(nutri_score)\n    nutri_score.append(score)\n#     total_score.append((1-nutrition_sensititvity)*new_outputs_np[i]+nutrition_sensititvity*nutri_score\ndomain2 = []\nratings_pred2 = []\ndomain2.append(np.min(nutri_score))\ndomain2.append(np.max(nutri_score))\nrng2 = 1\nif (domain2[1]-domain2[0])!=0:\n    rng2 = (domain2[1]-domain2[0])\nfor i in nutri_score:\n    ratings_pred2.append((i-domain2[0])/rng2)\n\ntotal_score = []\nfor i in range(len(ratings_pred2)):\n    total_score.append((1-nutrition_sensitivity)*ratings_pred[i]+nutrition_sensitivity*ratings_pred2[i])\n\nprint(total_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_recipes_indices = np.argsort(total_score)\nsorted_recipes_indices = np.flip(sorted_recipes_indices)\nprint(sorted_recipes_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_names = []\nfor idx in sorted_recipes_indices:\n    recipe = avail_recipes[idx]\n    sorted_names.append(df1.at[df1.index.values[df1['id']==recipe][0],'name'])\nprint(sorted_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}